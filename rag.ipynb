{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a8736c-dd0b-448b-8b8f-596e4b0b78a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f76563f9f1b49ecaca54a6f7e5b2af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing chunks:   0%|          | 0/2317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2317 chunks to the database.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1536,) and (3072,) not aligned: 1536 (dim 0) != 3072 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 100\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Test the retrieval\u001b[39;00m\n\u001b[0;32m     99\u001b[0m test_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat does Project 2025 say about BLM\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms move west?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 100\u001b[0m relevant_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mretrieve_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRelevant chunks for the query:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m relevant_chunks:\n",
      "Cell \u001b[1;32mIn[2], line 88\u001b[0m, in \u001b[0;36mretrieve_chunks\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m, emb \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     87\u001b[0m     emb_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(emb, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 88\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     similarities\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mid\u001b[39m, similarity))\n\u001b[0;32m     91\u001b[0m top_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(similarities, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:top_k]\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1536,) and (3072,) not aligned: 1536 (dim 0) != 3072 (dim 0)"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "# Import the API key and org ID from config.py\n",
    "try:\n",
    "    from config import OPENAI_API_KEY\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please create a config.py file with your OPENAI_API_KEY and OPENAI_ORG_ID\")\n",
    "\n",
    "# Set up OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Initialize database\n",
    "conn = sqlite3.connect('p2025_db.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS document_chunks\n",
    "(id INTEGER PRIMARY KEY, content TEXT, embedding BLOB)\n",
    "''')\n",
    "\n",
    "# Function to encode text using OpenAI with rate limiting\n",
    "def encode_text(text, max_retries=5, backoff_factor=1):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.embeddings.create(\n",
    "                model=\"text-embedding-ada-002\",\n",
    "                input=[text]\n",
    "            )\n",
    "            return np.array(response.data[0].embedding)\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            print(f\"Error occurred: {e}. Retrying in {backoff_factor * (2 ** attempt)} seconds...\")\n",
    "            time.sleep(backoff_factor * (2 ** attempt))\n",
    "\n",
    "# Function to add a chunk to the database\n",
    "def add_chunk(content, embedding):\n",
    "    cursor.execute('INSERT INTO document_chunks (content, embedding) VALUES (?, ?)',\n",
    "                   (content, embedding.tobytes()))\n",
    "    conn.commit()\n",
    "\n",
    "# Function to read and chunk the file\n",
    "def read_and_chunk_file(file_path, chunk_size=1000):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_size = 0\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            current_chunk.append(line)\n",
    "            current_size += len(line)\n",
    "            if current_size >= chunk_size:\n",
    "                chunks.append(''.join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_size = 0\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(''.join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Read and process the file\n",
    "chunks = read_and_chunk_file('p2025.txt')\n",
    "\n",
    "# Add chunks to the database with progress bar\n",
    "for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n",
    "    embedding = encode_text(chunk)\n",
    "    add_chunk(chunk, embedding)\n",
    "\n",
    "print(f\"Added {len(chunks)} chunks to the database.\")\n",
    "\n",
    "# Function to retrieve relevant chunks\n",
    "def retrieve_chunks(query, top_k=5):\n",
    "    query_embedding = encode_text(query)\n",
    "    \n",
    "    cursor.execute('SELECT id, embedding FROM document_chunks')\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    similarities = []\n",
    "    for id, emb in results:\n",
    "        emb_array = np.frombuffer(emb, dtype=np.float32)\n",
    "        similarity = np.dot(query_embedding, emb_array)\n",
    "        similarities.append((id, similarity))\n",
    "    \n",
    "    top_ids = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    placeholders = ','.join('?' for _ in top_ids)\n",
    "    cursor.execute(f'SELECT content FROM document_chunks WHERE id IN ({placeholders})', \n",
    "                   [id for id, _ in top_ids])\n",
    "    return cursor.fetchall()\n",
    "\n",
    "# Test the retrieval\n",
    "test_query = \"What does Project 2025 say about BLM's move west?\"\n",
    "relevant_chunks = retrieve_chunks(test_query)\n",
    "\n",
    "print(\"\\nRelevant chunks for the query:\")\n",
    "for chunk in relevant_chunks:\n",
    "    print(chunk[0][:200] + \"...\")  # Print first 200 characters of each chunk\n",
    "    print()\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7209c-fd68-4542-8817-8a9a212fc6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
