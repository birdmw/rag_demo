{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fc5d0b-38ca-4119-abd8-2531f9213550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import requests\n",
    "from requests.exceptions import Timeout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7856d2-d261-4227-ad4d-b440e65d2288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up OpenAI client...\n",
      "Initializing database...\n",
      "Creating tables if not exist...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x20d7129e640>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Import the API key from config.py\n",
    "try:\n",
    "    from config import OPENAI_API_KEY\n",
    "except ImportError:\n",
    "    raise ImportError(\"Please create a config.py file with your OPENAI_API_KEY\")\n",
    "\n",
    "print(\"Setting up OpenAI client...\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(\"Initializing database...\")\n",
    "conn = sqlite3.connect('premera_plan.sqlite')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"Creating tables if not exist...\")\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS document_chunks\n",
    "(id INTEGER PRIMARY KEY, content TEXT, embedding BLOB, shape TEXT, layer INTEGER)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41825b57-1805-4acd-9e50-c585c3c56f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_chunk_file(file_path, chunk_size=500, overlap=100):\n",
    "    print(f\"Reading file: {file_path}\")\n",
    "    chunks = []\n",
    "    #opening the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    print(f\"Chunking file (chunk size: {chunk_size}, overlap: {overlap})\")\n",
    "    start = 0\n",
    "    #looping through file chunk at a time\n",
    "    with tqdm(total=len(content), desc=\"Chunking progress\") as pbar:\n",
    "        while start < len(content):\n",
    "            end = start + chunk_size\n",
    "            chunk = content[start:end]\n",
    "            \n",
    "            if end < len(content):\n",
    "                #finds sentence end of chunk or paragraph end of chunk then moves end to that spot + 1 after new para or period\n",
    "                sentence_end = chunk.rfind('.')\n",
    "                paragraph_end = chunk.rfind('\\n')\n",
    "                if sentence_end > 0:\n",
    "                    end = start + sentence_end + 1\n",
    "                elif paragraph_end > 0:\n",
    "                    end = start + paragraph_end + 1\n",
    "            \n",
    "            chunks.append(content[start:end])\n",
    "            #new start will be the end but minus the overlap so we can include the overlap in the next chunk\n",
    "            start = end - overlap\n",
    "            pbar.update(end - start)\n",
    "    \n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb4601d-774d-440d-83e1-39080edf560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_pair(chunk1, chunk2):\n",
    "    system_message = \"You are an AI assistant tasked with summarizing text. Provide a concise summary that captures the key points of the given text.\"\n",
    "    user_message = f\"Summarize the following text:\\n\\n{chunk1}\\n\\n{chunk2}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f9c4d0-e1f8-42df-b954-bd51de051fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_pyramid(chunks, max_layers=5):\n",
    "    pyramid = [chunks]  # Bottom layer\n",
    "    \n",
    "    for layer in range(1, max_layers):\n",
    "        print(f\"Creating layer {layer}...\")\n",
    "        new_layer = []\n",
    "        for i in range(0, len(pyramid[-1]), 2):\n",
    "            if i + 1 < len(pyramid[-1]):\n",
    "                combined = summarize_pair(pyramid[-1][i], pyramid[-1][i+1])\n",
    "            else:\n",
    "                combined = pyramid[-1][i]  # If odd number, keep last chunk as is\n",
    "            new_layer.append(combined)\n",
    "        \n",
    "        pyramid.append(new_layer)\n",
    "        \n",
    "        if len(new_layer) == 1:\n",
    "            break  # We've reached the top of the pyramid\n",
    "    \n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee320f57-398a-4641-8502-dce5d31b6fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text, max_retries=10, backoff_factor=2, timeout=30):\n",
    "    print(f\"Starting to encode text of length {len(text)}\")\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1} to encode text\")\n",
    "            response = client.embeddings.create(\n",
    "                model=\"text-embedding-ada-002\",\n",
    "                input=[text],\n",
    "                timeout=timeout\n",
    "            )\n",
    "            embedding = np.array(response.data[0].embedding)\n",
    "            print(f\"Successfully encoded text\")\n",
    "            return embedding, embedding.shape\n",
    "        except Timeout:\n",
    "            wait_time = backoff_factor * (2 ** attempt)\n",
    "            print(f\"Request timed out. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "        except Exception as e:\n",
    "            wait_time = backoff_factor * (2 ** attempt)\n",
    "            print(f\"Error occurred: {e}. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "    print(\"Failed to encode text after all attempts\")\n",
    "    raise Exception(\"Failed to encode text after all attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed21692-1358-4bc1-9e67-c219f9e80280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and chunking file...\n",
      "Reading file: premera_paragraphs.txt\n",
      "Chunking file (chunk size: 500, overlap: 100)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f7960cef540adaacfa0a3941a0499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Chunking progress:   0%|          | 0/5888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 18 chunks\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading and chunking file...\")\n",
    "chunks = read_and_chunk_file('premera_paragraphs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a724cd-d388-43a8-8980-587716efb5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating summary pyramid...\n",
      "Creating layer 1...\n",
      "Creating layer 2...\n",
      "Creating layer 3...\n",
      "Creating layer 4...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating summary pyramid...\")\n",
    "pyramid = create_summary_pyramid(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd4246-6fb1-424d-a2bc-b6d6f3b56be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing chunks and adding to database...\")\n",
    "for layer, layer_chunks in enumerate(pyramid):\n",
    "    for chunk in tqdm(layer_chunks, desc=f\"Processing layer {layer}\"):\n",
    "        print(f\"Encoding chunk (length: {len(chunk)})\")\n",
    "        embedding, shape = encode_text(chunk)\n",
    "        print(f\"Adding chunk to database (embedding shape: {shape}, layer: {layer})\")\n",
    "        add_chunk(chunk, embedding, shape, layer)\n",
    "\n",
    "print(f\"Added {sum(len(layer) for layer in pyramid)} chunks to the database.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
